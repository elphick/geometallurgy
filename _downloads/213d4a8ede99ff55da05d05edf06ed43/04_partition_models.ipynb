{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Partition Models\n\nPartition models, (a.k.a. partition curves in the 1 dimensional case) define the separation of a unit operation /\nprocess.\n\nThe Partition Number (K) is represents the probability that a particle will report to the concentrate stream.\n\n\\begin{align}K = \\frac{{m_{concentrate}}}{{m_{feed}}}\\end{align}\n\nNote that the term \u201cconcentrate\u201d in the numerator can be misleading, as it does not always accurately represent\nthe desired or obtained fraction. For instance, in a screening operation, the numerator might be the \u201coversize\u201d\nrather than the \u201cconcentrate.\u201d To create a more universally applicable term for the numerator, we can redefine\nit as the \u201cpreferred fraction.\u201d This new terminology allows for a more inclusive and adaptable equation:\n\n\\begin{align}K = \\frac{{m_{preferred}}}{{m_{feed}}}\\end{align}\n\nConsider a desliming cyclone that aims to separate a slurry at 150 micron.  The preferred stream is defined as\nthe Underflow (UF), since that is the \"stream of interest\" in our simple example.\n\n..  Admonition:: TODO\n\n    Add a reference to partition curves.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from functools import partial\n\nimport numpy as np\nimport pandas as pd\nimport plotly\nimport plotly.graph_objects as go\nfrom scipy.interpolate import PchipInterpolator\n\nfrom elphick.geomet import IntervalSample\nfrom elphick.geomet.datasets.sample_data import size_by_assay\nfrom elphick.geomet.flowsheet import Flowsheet\nfrom elphick.geomet.utils.partition import napier_munn, napier_munn_size\nfrom elphick.geomet.utils.pandas import calculate_partition\n\n# sphinx_gallery_thumbnail_number = -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a mass-composition object\n\nWe get some demo data in the form of a pandas DataFrame\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df_data: pd.DataFrame = size_by_assay()\nmc_feed: IntervalSample = IntervalSample(df_data, name='size sample', moisture_in_scope=False)\nprint(mc_feed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define and Apply the Partition\n\nWe partially initialise the partition function.  The unfilled argument must be named the same as the index in the\nIntervalSample object upon which the partition is applied.  In this example the unfilled argument is 'size',\nso the partition will be applied to the size dimension of the index.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "part_cyclone = partial(napier_munn_size, d50=0.150, ep=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Separate the object using the defined partitions.  UF = Underflow, OF = Overflow\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mc_uf, mc_of = mc_feed.split_by_partition(partition_definition=part_cyclone, name_1='underflow', name_2='overflow')\nfs: Flowsheet = Flowsheet().from_objects([mc_feed, mc_uf, mc_of])\n\nfig = fs.table_plot(table_pos='left',\n                    sankey_color_var='Fe', sankey_edge_colormap='copper_r', sankey_vmin=50, sankey_vmax=70)\nfig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll now get the partition data from the objects\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df_partition: pd.DataFrame = mc_feed.calculate_partition(preferred=mc_uf)\ndf_partition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create an interpolator from the data.  As a Callable, the spline can be used to split a MassComposition object.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "size_grid = np.linspace(0.01, df_partition.index.right.max(), num=500)\nspline_partition = PchipInterpolator(x=df_partition.sort_index()['size'], y=df_partition.sort_index()['K'])\npn_extracted = spline_partition(size_grid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the extracted data, and the spline on the input partition curve to visually validate.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pn_original = part_cyclone(size_grid)\n\nfig = go.Figure(go.Scatter(x=size_grid, y=pn_original, name='Input Partition', line=dict(width=5, color='DarkSlateGrey')))\nfig.add_trace(go.Scatter(x=df_partition['size'], y=df_partition['K'], name='Extracted Partition Data', mode='markers',\n                         marker=dict(size=12, color='red', line=dict(width=2, color='DarkSlateGrey'))))\nfig.add_trace(\n    go.Scatter(x=size_grid, y=pn_extracted, name='Extracted Partition Curve', line=dict(width=2, color='red', dash='dash')))\n\nfig.update_xaxes(type=\"log\")\nfig.update_layout(title='Partition Round Trip Check', xaxis_title='da', yaxis_title='K', yaxis_range=[0, 1.05])\n\n# noinspection PyTypeChecker\nplotly.io.show(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are minor differences between the interpolated spline curve and the Napier-Munn input partition.\nHowever, the data points all lie on both curves.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pandas Function\n\nThe partition functionality is available as a pandas function also.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df_partition_2: pd.DataFrame = mc_feed.data.pipe(calculate_partition, df_preferred=mc_uf.data, col_mass_dry='mass_dry')\ndf_partition_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pd.testing.assert_frame_equal(df_partition, df_partition_2)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}